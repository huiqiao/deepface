{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface.commons import image_utils\n",
    "from deepface.modules import modeling, detection, preprocessing\n",
    "from deepface.models.FacialRecognition import FacialRecognition\n",
    "from deepface.models.Detector import DetectedFace, FacialAreaRegion\n",
    "from deepface.detectors import DetectorWrapper\n",
    "from deepface.detectors import MtCnn\n",
    "from deepface.basemodels import ArcFace\n",
    "from deepface.commons import image_utils\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Any, Dict, Optional, Union, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "face_recog_model = 'ArcFace'\n",
    "face_detect_model = 'mtcnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector_client = MtCnn.MtCnnClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognition_client = ArcFace.ArcFaceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection \n",
    "\n",
    "def align_face(\n",
    "    img: np.ndarray,\n",
    "    left_eye: Union[list, tuple],\n",
    "    right_eye: Union[list, tuple],\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Align a given image horizantally with respect to their left and right eye locations\n",
    "    Args:\n",
    "        img (np.ndarray): pre-loaded image with detected face\n",
    "        left_eye (list or tuple): coordinates of left eye with respect to the person itself\n",
    "        right_eye(list or tuple): coordinates of right eye with respect to the person itself\n",
    "    Returns:\n",
    "        img (np.ndarray): aligned facial image\n",
    "    \"\"\"\n",
    "    # if eye could not be detected for the given image, return image itself\n",
    "    if left_eye is None or right_eye is None:\n",
    "        return img, 0\n",
    "\n",
    "    # sometimes unexpectedly detected images come with nil dimensions\n",
    "    if img.shape[0] == 0 or img.shape[1] == 0:\n",
    "        return img, 0\n",
    "\n",
    "    angle = float(np.degrees(np.arctan2(left_eye[1] - right_eye[1], left_eye[0] - right_eye[0])))\n",
    "    img = np.array(Image.fromarray(img).rotate(angle))\n",
    "    return img, angle\n",
    "\n",
    "def rotate_facial_area(\n",
    "    facial_area: Tuple[int, int, int, int], angle: float, size: Tuple[int, int]\n",
    ") -> Tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Rotate the facial area around its center.\n",
    "    Inspried from the work of @UmutDeniz26 - github.com/serengil/retinaface/pull/80\n",
    "\n",
    "    Args:\n",
    "        facial_area (tuple of int): Representing the (x1, y1, x2, y2) of the facial area.\n",
    "            x2 is equal to x1 + w1, and y2 is equal to y1 + h1\n",
    "        angle (float): Angle of rotation in degrees. Its sign determines the direction of rotation.\n",
    "                       Note that angles > 360 degrees are normalized to the range [0, 360).\n",
    "        size (tuple of int): Tuple representing the size of the image (width, height).\n",
    "\n",
    "    Returns:\n",
    "        rotated_coordinates (tuple of int): Representing the new coordinates\n",
    "            (x1, y1, x2, y2) or (x1, y1, x1+w1, y1+h1) of the rotated facial area.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize the witdh of the angle so we don't have to\n",
    "    # worry about rotations greater than 360 degrees.\n",
    "    # We workaround the quirky behavior of the modulo operator\n",
    "    # for negative angle values.\n",
    "    direction = 1 if angle >= 0 else -1\n",
    "    angle = abs(angle) % 360\n",
    "    if angle == 0:\n",
    "        return facial_area\n",
    "\n",
    "    # Angle in radians\n",
    "    angle = angle * np.pi / 180\n",
    "\n",
    "    height, weight = size\n",
    "\n",
    "    # Translate the facial area to the center of the image\n",
    "    x = (facial_area[0] + facial_area[2]) / 2 - weight / 2\n",
    "    y = (facial_area[1] + facial_area[3]) / 2 - height / 2\n",
    "\n",
    "    # Rotate the facial area\n",
    "    x_new = x * np.cos(angle) + y * direction * np.sin(angle)\n",
    "    y_new = -x * direction * np.sin(angle) + y * np.cos(angle)\n",
    "\n",
    "    # Translate the facial area back to the original position\n",
    "    x_new = x_new + weight / 2\n",
    "    y_new = y_new + height / 2\n",
    "\n",
    "    # Calculate projected coordinates after alignment\n",
    "    x1 = x_new - (facial_area[2] - facial_area[0]) / 2\n",
    "    y1 = y_new - (facial_area[3] - facial_area[1]) / 2\n",
    "    x2 = x_new + (facial_area[2] - facial_area[0]) / 2\n",
    "    y2 = y_new + (facial_area[3] - facial_area[1]) / 2\n",
    "\n",
    "    # validate projected coordinates are in image's boundaries\n",
    "    x1 = max(int(x1), 0)\n",
    "    y1 = max(int(y1), 0)\n",
    "    x2 = min(int(x2), weight)\n",
    "    y2 = min(int(y2), height)\n",
    "\n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "def detect_faces(img: np.ndarray, align: bool = True, expand_percentage: int = 0) -> List[DetectedFace]:\n",
    "    \"\"\"\n",
    "    Detect face(s) from a given image\n",
    "    Args:\n",
    "        img (np.ndarray): pre-loaded image\n",
    "\n",
    "        align (bool): enable or disable alignment after detection\n",
    "\n",
    "        expand_percentage (int): expand detected facial area with a percentage (default is 0).\n",
    "\n",
    "    Returns:\n",
    "        results (List[DetectedFace]): A list of DetectedFace objects\n",
    "            where each object contains:\n",
    "\n",
    "        - img (np.ndarray): The detected face as a NumPy array.\n",
    "\n",
    "        - facial_area (FacialAreaRegion): The facial area region represented as x, y, w, h,\n",
    "            left_eye and right eye. left eye and right eye are eyes on the left and right\n",
    "            with respect to the person instead of observer.\n",
    "\n",
    "        - confidence (float): The confidence score associated with the detected face.\n",
    "    \"\"\"\n",
    "    # validate expand percentage score\n",
    "    if expand_percentage < 0:\n",
    "        logger.warn(\n",
    "            f\"Expand percentage cannot be negative but you set it to {expand_percentage}.\"\n",
    "            \"Overwritten it to 0.\"\n",
    "        )\n",
    "        expand_percentage = 0\n",
    "\n",
    "    # find facial areas of given image\n",
    "    facial_areas = face_detector_client.detect_faces(img)\n",
    "\n",
    "    results = []\n",
    "    for facial_area in facial_areas:\n",
    "        x = facial_area.x\n",
    "        y = facial_area.y\n",
    "        w = facial_area.w\n",
    "        h = facial_area.h\n",
    "        left_eye = facial_area.left_eye\n",
    "        right_eye = facial_area.right_eye\n",
    "        confidence = facial_area.confidence\n",
    "\n",
    "        if expand_percentage > 0:\n",
    "            # Expand the facial region height and width by the provided percentage\n",
    "            # ensuring that the expanded region stays within img.shape limits\n",
    "            expanded_w = w + int(w * expand_percentage / 100)\n",
    "            expanded_h = h + int(h * expand_percentage / 100)\n",
    "\n",
    "            x = max(0, x - int((expanded_w - w) / 2))\n",
    "            y = max(0, y - int((expanded_h - h) / 2))\n",
    "            w = min(img.shape[1] - x, expanded_w)\n",
    "            h = min(img.shape[0] - y, expanded_h)\n",
    "\n",
    "        # extract detected face unaligned\n",
    "        detected_face = img[int(y) : int(y + h), int(x) : int(x + w)]\n",
    "\n",
    "        # align original image, then find projection of detected face area after alignment\n",
    "        if align is True:  # and left_eye is not None and right_eye is not None:\n",
    "            aligned_img, angle = align_face(\n",
    "                img=img, left_eye=left_eye, right_eye=right_eye\n",
    "            )\n",
    "            rotated_x1, rotated_y1, rotated_x2, rotated_y2 = rotate_facial_area(\n",
    "                facial_area=(x, y, x + w, y + h), angle=angle, size=(img.shape[0], img.shape[1])\n",
    "            )\n",
    "            detected_face = aligned_img[\n",
    "                int(rotated_y1) : int(rotated_y2), int(rotated_x1) : int(rotated_x2)\n",
    "            ]\n",
    "\n",
    "        result = DetectedFace(\n",
    "            img=detected_face,\n",
    "            facial_area=FacialAreaRegion(\n",
    "                x=x, y=y, h=h, w=w, confidence=confidence, left_eye=left_eye, right_eye=right_eye\n",
    "            ),\n",
    "            confidence=confidence,\n",
    "        )\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def extract_faces(\n",
    "    img_path: Union[str, np.ndarray],\n",
    "    enforce_detection: bool = True,\n",
    "    align: bool = True,\n",
    "    expand_percentage: int = 0,\n",
    "    grayscale: bool = False,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \n",
    "    resp_objs = []\n",
    "\n",
    "    # img might be path, base64 or numpy array. Convert it to numpy whatever it is.\n",
    "    img, img_name = image_utils.load_image(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Exception while loading {img_name}\")\n",
    "\n",
    "    base_region = FacialAreaRegion(x=0, y=0, w=img.shape[1], h=img.shape[0], confidence=0)\n",
    "\n",
    "    face_objs = detect_faces(\n",
    "        img=img,\n",
    "        align=align,\n",
    "        expand_percentage=expand_percentage,\n",
    "    )\n",
    "    \n",
    "\n",
    "    # in case of no face found\n",
    "    if len(face_objs) == 0 and enforce_detection is True:\n",
    "        if img_name is not None:\n",
    "            raise ValueError(\n",
    "                f\"Face could not be detected in {img_name}.\"\n",
    "                \"Please confirm that the picture is a face photo \"\n",
    "                \"or consider to set enforce_detection param to False.\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Face could not be detected. Please confirm that the picture is a face photo \"\n",
    "                \"or consider to set enforce_detection param to False.\"\n",
    "            )\n",
    "\n",
    "    if len(face_objs) == 0 and enforce_detection is False:\n",
    "        face_objs = [DetectedFace(img=img, facial_area=base_region, confidence=0)]\n",
    "\n",
    "    for face_obj in face_objs:\n",
    "        current_img = face_obj.img\n",
    "        current_region = face_obj.facial_area\n",
    "\n",
    "        if current_img.shape[0] == 0 or current_img.shape[1] == 0:\n",
    "            continue\n",
    "\n",
    "        if grayscale is True:\n",
    "            current_img = cv2.cvtColor(current_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        current_img = current_img / 255  # normalize input in [0, 1]\n",
    "\n",
    "        resp_objs.append(\n",
    "            {\n",
    "                \"face\": current_img[:, :, ::-1],\n",
    "                \"facial_area\": {\n",
    "                    \"x\": int(current_region.x),\n",
    "                    \"y\": int(current_region.y),\n",
    "                    \"w\": int(current_region.w),\n",
    "                    \"h\": int(current_region.h),\n",
    "                    \"left_eye\": current_region.left_eye,\n",
    "                    \"right_eye\": current_region.right_eye,\n",
    "                },\n",
    "                \"confidence\": round(current_region.confidence, 2),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if len(resp_objs) == 0 and enforce_detection == True:\n",
    "        raise ValueError(\n",
    "            f\"Exception while extracting faces from {img_name}.\"\n",
    "            \"Consider to set enforce_detection arg to False.\"\n",
    "        )\n",
    "\n",
    "    return resp_objs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face feature extraction\n",
    "\n",
    "def extract_faces_and_embeddings(\n",
    "    img_path: Union[str, np.ndarray],\n",
    "    enforce_detection: bool = True,\n",
    "    align: bool = True,\n",
    "    expand_percentage: int = 0,\n",
    "    normalization: str = \"base\",\n",
    ") -> Tuple[List[List[float]], List[dict]]:\n",
    "    \"\"\"\n",
    "    Extract facial areas and find corresponding embeddings for given image\n",
    "    Returns:\n",
    "        embeddings (List[float])\n",
    "        facial areas (List[dict])\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    facial_areas = []\n",
    "\n",
    "    # detect faces\n",
    "    img_objs = extract_faces(\n",
    "        img_path=img_path,\n",
    "        grayscale=False,\n",
    "        enforce_detection=enforce_detection,\n",
    "        align=align,\n",
    "        expand_percentage=expand_percentage,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # find embeddings for each face\n",
    "    for img_obj in img_objs:        \n",
    "        img = img_obj[\"face\"]\n",
    "\n",
    "        # rgb to bgr\n",
    "        img = img[:, :, ::-1]\n",
    "\n",
    "\n",
    "        # we have run pre-process in verification. so, this can be skipped if it is coming from verify.\n",
    "        target_size = face_recognition_client.input_shape\n",
    "        # resize to expected shape of ml model\n",
    "        img = preprocessing.resize_image(\n",
    "            img=img,\n",
    "            # thanks to DeepId (!)\n",
    "            target_size=(target_size[1], target_size[0]),\n",
    "        )\n",
    "\n",
    "        # custom normalization\n",
    "        img = preprocessing.normalize_input(img=img, normalization=normalization)\n",
    "\n",
    "        embedding = face_recognition_client.forward(img)\n",
    "        embeddings.append(embedding)\n",
    "        facial_areas.append(img_obj[\"facial_area\"])\n",
    "\n",
    "    return embeddings, facial_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cosine_distance(\n",
    "    source_representation: Union[np.ndarray, list], test_representation: Union[np.ndarray, list]\n",
    ") -> np.float64:\n",
    "    \"\"\"\n",
    "    Find cosine distance between two given vectors\n",
    "    Args:\n",
    "        source_representation (np.ndarray or list): 1st vector\n",
    "        test_representation (np.ndarray or list): 2nd vector\n",
    "    Returns\n",
    "        distance (np.float64): calculated cosine distance\n",
    "    \"\"\"\n",
    "    if isinstance(source_representation, list):\n",
    "        source_representation = np.array(source_representation)\n",
    "\n",
    "    if isinstance(test_representation, list):\n",
    "        test_representation = np.array(test_representation)\n",
    "\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pair zxl_1.jpg-zxl_2.jpg is same person, Distance: 0.3385937740158439\n",
      "✅ Pair zxl_1.jpg-zt_1.jpg is different persons, Distance: 0.6192383744209936\n",
      "✅ Pair jyz_1.jpg-jyz_2.jpg is same person, Distance: 0.28493035294999614\n",
      "✅ Pair zxl_1.jpg-jyz_1.jpg is different persons, Distance: 0.7327641113834089\n",
      "✅ Pair wj_1.jpg-wj_2.jpg is same person, Distance: 0.40727009046274076\n",
      "✅ Pair wj_1.jpg-wj_3.jpg is same person, Distance: 0.24609952886567377\n",
      "✅ Pair lsm_1.jpg-lsm_2.jpg is same person, Distance: 0.5068068690820959\n",
      "✅ Pair lsm_1.jpg-zxl_2.jpg is different persons, Distance: 1.0429172228115027\n",
      "✅ Pair zxl_1.jpg-wj_1.jpg is different persons, Distance: 0.7808340290531035\n",
      "coverage_score 100.0\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "threshold = 0.6 # threshold from Arcface consine distance model recommendation\n",
    "test_set = [\n",
    "    [\"testset/zxl_1.jpg\", \"testset/zxl_2.jpg\", True],\n",
    "    [\"testset/zxl_1.jpg\", \"testset/zt_1.jpg\", False],\n",
    "    [\"testset/jyz_1.jpg\", \"testset/jyz_2.jpg\", True],\n",
    "    [\"testset/zxl_1.jpg\", \"testset/jyz_1.jpg\", False],\n",
    "    [\"testset/wj_1.jpg\", \"testset/wj_2.jpg\", True],\n",
    "    [\"testset/wj_1.jpg\", \"testset/wj_3.jpg\", True],\n",
    "    [\"testset/lsm_1.jpg\", \"testset/lsm_2.jpg\", True],\n",
    "    [\"testset/lsm_1.jpg\", \"testset/zxl_2.jpg\", False],\n",
    "    [\"testset/zxl_1.jpg\", \"testset/wj_1.jpg\", False],\n",
    "]\n",
    "\n",
    "successful_tests = 0\n",
    "unsuccessful_tests = 0\n",
    "for pair in test_set:\n",
    "    img1_embeddings, img1_facial_areas = extract_faces_and_embeddings(pair[0])\n",
    "    img2_embeddings, img2_facial_areas = extract_faces_and_embeddings(pair[1])\n",
    "    ture_label = pair[2]\n",
    "    distance = find_cosine_distance(img1_embeddings[0], img2_embeddings[0])\n",
    "    label = (distance <= threshold)\n",
    "    if label == ture_label:\n",
    "        test_result_label = \"✅\"\n",
    "        successful_tests += 1\n",
    "    else:\n",
    "        test_result_label = \"❌\"\n",
    "        unsuccessful_tests += 1\n",
    "\n",
    "    if label:\n",
    "        classified_label = \"same person\"\n",
    "    else:\n",
    "        classified_label = \"different persons\"\n",
    "\n",
    "    img1_alias = pair[0].split(\"/\", maxsplit=1)[-1]\n",
    "    img2_alias = pair[1].split(\"/\", maxsplit=1)[-1]\n",
    "\n",
    "    print(f\"{test_result_label} Pair {img1_alias}-{img2_alias} is {classified_label}, Distance: {distance}\",)\n",
    "toc = time.time()\n",
    "\n",
    "coverage_score = (100 * successful_tests) / (successful_tests + unsuccessful_tests)\n",
    "print(f'coverage_score {coverage_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_path = 'testset/'\n",
    "files = os.listdir(test_path)\n",
    "embeds = []\n",
    "for file in files:\n",
    "    img_path = f'{test_path}{file}'\n",
    "    img_embeddings, img_facial_areas = extract_faces_and_embeddings(img_path)\n",
    "    embeds.append(img_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pair zxl_1.jpg-zxl_2.jpg is same person, Distance: 0.34\n",
      "✅ Pair zxl_2.jpg-zxl_1.jpg is same person, Distance: 0.34\n",
      "✅ Pair zt_1.jpg-zt_2.jpg is same person, Distance: 0.43\n",
      "✅ Pair zt_2.jpg-zt_1.jpg is same person, Distance: 0.43\n",
      "✅ Pair wj_1.jpg-wj_2.jpg is same person, Distance: 0.41\n",
      "✅ Pair wj_1.jpg-wj_3.jpg is same person, Distance: 0.25\n",
      "✅ Pair wj_2.jpg-wj_1.jpg is same person, Distance: 0.41\n",
      "✅ Pair wj_2.jpg-wj_3.jpg is same person, Distance: 0.35\n",
      "✅ Pair wj_3.jpg-wj_1.jpg is same person, Distance: 0.25\n",
      "✅ Pair wj_3.jpg-wj_2.jpg is same person, Distance: 0.35\n",
      "✅ Pair lsm_1.jpg-lsm_2.jpg is same person, Distance: 0.51\n",
      "✅ Pair lsm_2.jpg-lsm_1.jpg is same person, Distance: 0.51\n",
      "✅ Pair jyz_1.jpg-jyz_2.jpg is same person, Distance: 0.28\n",
      "✅ Pair jyz_2.jpg-jyz_1.jpg is same person, Distance: 0.28\n",
      "✅ Pair ax_2.jpg-ax_1.jpg is same person, Distance: 0.33\n",
      "✅ Pair ax_1.jpg-ax_2.jpg is same person, Distance: 0.33\n",
      "✅ Pair cjx_3.jpg-cjx_1.jpg is same person, Distance: 0.35\n",
      "✅ Pair cjx_3.jpg-cjx_2.jpg is same person, Distance: 0.27\n",
      "✅ Pair cjx_1.jpg-cjx_3.jpg is same person, Distance: 0.35\n",
      "✅ Pair cjx_1.jpg-cjx_2.jpg is same person, Distance: 0.33\n",
      "✅ Pair cxz_2.jpg-cxz_1.jpg is same person, Distance: 0.32\n",
      "✅ Pair cjx_2.jpg-cjx_3.jpg is same person, Distance: 0.27\n",
      "✅ Pair cjx_2.jpg-cjx_1.jpg is same person, Distance: 0.33\n",
      "✅ Pair cxz_1.jpg-cxz_2.jpg is same person, Distance: 0.32\n",
      "✅ Pair ghl_1.jpg-ghl_2.jpg is same person, Distance: 0.34\n",
      "✅ Pair ghl_1.jpg-ghl_3.jpg is same person, Distance: 0.30\n",
      "✅ Pair ghl_2.jpg-ghl_1.jpg is same person, Distance: 0.34\n",
      "✅ Pair ghl_2.jpg-ghl_3.jpg is same person, Distance: 0.40\n",
      "✅ Pair ghl_3.jpg-ghl_1.jpg is same person, Distance: 0.30\n",
      "✅ Pair ghl_3.jpg-ghl_2.jpg is same person, Distance: 0.40\n",
      "✅ Pair jss_2.jpg-jss_1.jpg is same person, Distance: 0.34\n",
      "✅ Pair jss_1.jpg-jss_2.jpg is same person, Distance: 0.34\n",
      "✅ Pair lal_3.jpg-lal_1.jpg is same person, Distance: 0.38\n",
      "✅ Pair lal_3.jpg-lal_2.jpg is same person, Distance: 0.49\n",
      "✅ Pair lal_1.jpg-lal_3.jpg is same person, Distance: 0.38\n",
      "✅ Pair lal_1.jpg-lal_2.jpg is same person, Distance: 0.45\n",
      "✅ Pair lal_2.jpg-lal_3.jpg is same person, Distance: 0.49\n",
      "✅ Pair lal_2.jpg-lal_1.jpg is same person, Distance: 0.45\n",
      "✅ Pair lqy_2.jpg-lqy_1.jpg is same person, Distance: 0.44\n",
      "✅ Pair lqy_1.jpg-lqy_2.jpg is same person, Distance: 0.44\n",
      "✅ Pair lz_2.jpg-lz_1.jpg is same person, Distance: 0.43\n",
      "✅ Pair lz_1.jpg-lz_2.jpg is same person, Distance: 0.43\n",
      "✅ Pair myq_3.jpg-myq_1.jpg is same person, Distance: 0.43\n",
      "✅ Pair myq_3.jpg-myq_2.jpg is same person, Distance: 0.35\n",
      "✅ Pair myq_1.jpg-myq_3.jpg is same person, Distance: 0.43\n",
      "✅ Pair myq_1.jpg-myq_2.jpg is same person, Distance: 0.43\n",
      "✅ Pair myq_2.jpg-myq_3.jpg is same person, Distance: 0.35\n",
      "✅ Pair myq_2.jpg-myq_1.jpg is same person, Distance: 0.43\n",
      "✅ Pair wjj_1.jpg-wjj_2.jpg is same person, Distance: 0.33\n",
      "✅ Pair wjj_2.jpg-wjj_1.jpg is same person, Distance: 0.33\n",
      "✅ Pair wyp_3.jpg-wyp_4.jpg is same person, Distance: 0.54\n",
      "❌ Pair wyp_3.jpg-wyp_2.jpg is different persons, Distance: 0.68\n",
      "❌ Pair wyp_3.jpg-wyp_1.jpg is different persons, Distance: 0.61\n",
      "✅ Pair wyp_4.jpg-wyp_3.jpg is same person, Distance: 0.54\n",
      "✅ Pair wyp_4.jpg-wyp_2.jpg is same person, Distance: 0.54\n",
      "✅ Pair wyp_4.jpg-wyp_1.jpg is same person, Distance: 0.29\n",
      "❌ Pair wyp_2.jpg-wyp_3.jpg is different persons, Distance: 0.68\n",
      "✅ Pair wyp_2.jpg-wyp_4.jpg is same person, Distance: 0.54\n",
      "✅ Pair wyp_2.jpg-wyp_1.jpg is same person, Distance: 0.50\n",
      "❌ Pair wyp_1.jpg-wyp_3.jpg is different persons, Distance: 0.61\n",
      "✅ Pair wyp_1.jpg-wyp_4.jpg is same person, Distance: 0.29\n",
      "✅ Pair wyp_1.jpg-wyp_2.jpg is same person, Distance: 0.50\n",
      "✅ Pair xyn_1.jpg-xyn_2.jpg is same person, Distance: 0.21\n",
      "✅ Pair xyn_2.jpg-xyn_1.jpg is same person, Distance: 0.21\n",
      "✅ Pair zcy_1.jpg-zcy_2.jpg is same person, Distance: 0.41\n",
      "✅ Pair zcy_2.jpg-zcy_1.jpg is same person, Distance: 0.41\n",
      "✅ Pair zjf_1.jpg-zjf_2.jpg is same person, Distance: 0.60\n",
      "✅ Pair zjf_2.jpg-zjf_1.jpg is same person, Distance: 0.60\n",
      "✅ Pair zq_2.jpg-zq_1.jpg is same person, Distance: 0.56\n",
      "✅ Pair zy_1.jpg-zy_2.jpg is same person, Distance: 0.22\n",
      "✅ Pair zy_2.jpg-zy_1.jpg is same person, Distance: 0.22\n",
      "❌ Pair gyx_1.jpg-gyx_2.jpg is different persons, Distance: 0.65\n",
      "✅ Pair gyx_1.jpg-gyx_3.jpg is same person, Distance: 0.26\n",
      "✅ Pair zq_1.jpg-zq_2.jpg is same person, Distance: 0.56\n",
      "❌ Pair gyx_2.jpg-gyx_1.jpg is different persons, Distance: 0.65\n",
      "✅ Pair gyx_2.jpg-gyx_3.jpg is same person, Distance: 0.52\n",
      "✅ Pair gyx_3.jpg-gyx_1.jpg is same person, Distance: 0.26\n",
      "✅ Pair gyx_3.jpg-gyx_2.jpg is same person, Distance: 0.52\n",
      "✅ Pair cqj_1.jpg-cqj_2.jpg is same person, Distance: 0.34\n",
      "✅ Pair cqj_2.jpg-cqj_1.jpg is same person, Distance: 0.34\n",
      "✅ Pair ljj_1.jpg-ljj_2.jpg is same person, Distance: 0.45\n",
      "✅ Pair ljj_2.jpg-ljj_1.jpg is same person, Distance: 0.45\n",
      "✅ Pair lyt_4.jpg-lyt_2.jpg is same person, Distance: 0.27\n",
      "✅ Pair lyt_4.jpg-lyt_3.jpg is same person, Distance: 0.38\n",
      "✅ Pair lyt_4.jpg-lyt_1.jpg is same person, Distance: 0.52\n",
      "✅ Pair lyt_2.jpg-lyt_4.jpg is same person, Distance: 0.27\n",
      "✅ Pair lyt_2.jpg-lyt_3.jpg is same person, Distance: 0.41\n",
      "✅ Pair lyt_2.jpg-lyt_1.jpg is same person, Distance: 0.60\n",
      "✅ Pair lyt_3.jpg-lyt_4.jpg is same person, Distance: 0.38\n",
      "✅ Pair lyt_3.jpg-lyt_2.jpg is same person, Distance: 0.41\n",
      "✅ Pair lyt_3.jpg-lyt_1.jpg is same person, Distance: 0.58\n",
      "✅ Pair lyt_1.jpg-lyt_4.jpg is same person, Distance: 0.52\n",
      "✅ Pair lyt_1.jpg-lyt_2.jpg is same person, Distance: 0.60\n",
      "✅ Pair lyt_1.jpg-lyt_3.jpg is same person, Distance: 0.58\n",
      "✅ Pair myc_3.jpeg-myc_1.jpg is same person, Distance: 0.35\n",
      "✅ Pair myc_3.jpeg-myc_2.jpg is same person, Distance: 0.39\n",
      "✅ Pair myc_1.jpg-myc_3.jpeg is same person, Distance: 0.35\n",
      "✅ Pair myc_1.jpg-myc_2.jpg is same person, Distance: 0.41\n",
      "✅ Pair myc_2.jpg-myc_3.jpeg is same person, Distance: 0.39\n",
      "✅ Pair myc_2.jpg-myc_1.jpg is same person, Distance: 0.41\n",
      "✅ Pair tp_2.jpg-tp_1.jpg is same person, Distance: 0.31\n",
      "✅ Pair tp_1.jpg-tp_2.jpg is same person, Distance: 0.31\n",
      "✅ Pair tzc_1.jpg-tzc_2.jpg is same person, Distance: 0.32\n",
      "✅ Pair tzc_2.jpg-tzc_1.jpg is same person, Distance: 0.32\n",
      "✅ Pair wyz_1.jpg-wyz_2.jpg is same person, Distance: 0.45\n",
      "✅ Pair wyz_2.jpg-wyz_1.jpg is same person, Distance: 0.45\n",
      "✅ Pair xys_1.jpg-xys_2.jpg is same person, Distance: 0.21\n",
      "✅ Pair xys_2.jpg-xys_1.jpg is same person, Distance: 0.21\n",
      "✅ Pair zjh_1.jpg-zjh_2.jpg is same person, Distance: 0.29\n",
      "✅ Pair zjh_1.jpg-zjh_3.jpg is same person, Distance: 0.17\n",
      "✅ Pair zjh_2.jpg-zjh_1.jpg is same person, Distance: 0.29\n",
      "✅ Pair zjh_2.jpg-zjh_3.jpg is same person, Distance: 0.33\n",
      "✅ Pair zjh_3.jpg-zjh_1.jpg is same person, Distance: 0.17\n",
      "✅ Pair zjh_3.jpg-zjh_2.jpg is same person, Distance: 0.33\n",
      "❌ Pair zx_1.jpg-zx_2.jpg is different persons, Distance: 0.68\n",
      "❌ Pair zx_2.jpg-zx_1.jpg is different persons, Distance: 0.68\n",
      "✅ Pair zp_2.jpg-zp_1.jpg is same person, Distance: 0.46\n",
      "✅ Pair zp_1.jpg-zp_2.jpg is same person, Distance: 0.46\n",
      "✅ Pair zw_1.jpg-zw_2.jpg is same person, Distance: 0.29\n",
      "✅ Pair zw_2.jpg-zw_1.jpg is same person, Distance: 0.29\n",
      "✅ Pair zzd_1.jpg-zzd_2.jpg is same person, Distance: 0.56\n",
      "✅ Pair zzd_2.jpg-zzd_1.jpg is same person, Distance: 0.56\n",
      "✅ Pair pyc_1.jpg-pyc_2.jpg is same person, Distance: 0.31\n",
      "✅ Pair pyc_2.jpg-pyc_1.jpg is same person, Distance: 0.31\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_error = 0\n",
    "for i in range(len(embeds)):\n",
    "    for j in range(len(embeds)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        distance = find_cosine_distance(embeds[i], embeds[j])\n",
    "        label = (distance <= threshold)\n",
    "        true_label = (files[i].split('_')[0] == files[j].split('_')[0])\n",
    "        if label == true_label:\n",
    "            test_result_label = \"✅\"\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            test_result_label = \"❌\"\n",
    "            num_error += 1\n",
    "\n",
    "        if label:\n",
    "            classified_label = \"same person\"\n",
    "        else:\n",
    "            classified_label = \"different persons\"\n",
    "\n",
    "        if true_label:\n",
    "            print(f\"{test_result_label} Pair {files[i]}-{files[j]} is {classified_label}, Distance: {distance:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = find_cosine_distance(embeds[0], embeds[1])\n",
    "label = (distance <= threshold)\n",
    "true_label = (files[0].split('_')[0] == files[1].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3385937740158439, True, True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance, label, true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
